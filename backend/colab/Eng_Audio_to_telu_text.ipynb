{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqIR8DdXtT_5",
        "outputId": "ed4289c1-6001-42eb-fba4-1a7d4ced1cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-2agx3m8d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-2agx3m8d\n",
            "  Resolved https://github.com/openai/whisper.git to commit 90db0de1896c23cbfaf0c58bc2d30665f709f170\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJG6eyZftcgd",
        "outputId": "eb6a49e4-752c-4ef8-ad03-3af033da34f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import whisper\n",
        "import warnings\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, MarianMTModel, MarianTokenizer\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "4fkVlFiztlbW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Whisper model (choose 'small', 'medium', or 'large' for better accuracy)\n",
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "id": "PdGVlMFutwJg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translation models and tokenizers setup\n",
        "nllb_model_name = \"facebook/nllb-200-distilled-1.3B\"\n",
        "nllb_tokenizer = AutoTokenizer.from_pretrained(nllb_model_name)\n",
        "nllb_model = AutoModelForSeq2SeqLM.from_pretrained(nllb_model_name)"
      ],
      "metadata": {
        "id": "8VX2toJct42v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to split long text into chunks\n",
        "def split_text_into_chunks(text, max_tokens, tokenizer):\n",
        "    tokens = tokenizer.encode(text)\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), max_tokens):\n",
        "        chunk_tokens = tokens[i:i + max_tokens]\n",
        "        chunks.append(tokenizer.decode(chunk_tokens, skip_special_tokens=True))\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "8nVBMY1Pj4ON"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to translate chunks of text\n",
        "def translate_chunks(chunks, translation_function):\n",
        "    translated_chunks = [translation_function(chunk) for chunk in chunks]\n",
        "    return \" \".join(translated_chunks)"
      ],
      "metadata": {
        "id": "qT42PY7Lj6un"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrapper function for large text translation\n",
        "def translate_large_text(text, translation_function, tokenizer, max_tokens=512):\n",
        "    chunks = split_text_into_chunks(text, max_tokens, tokenizer)\n",
        "    translated_text = translate_chunks(chunks, translation_function)\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "YtUSsqDEkBvX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def english_to_telugu(text):\n",
        "    src_lang = \"eng_Latn\"\n",
        "    tgt_lang = \"tel_Telu\"\n",
        "    nllb_tokenizer.src_lang = src_lang\n",
        "    inputs = nllb_tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "    outputs = nllb_model.generate(**inputs, forced_bos_token_id=nllb_tokenizer.convert_tokens_to_ids(tgt_lang))\n",
        "    return nllb_tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "4IwXaML8uGKH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_and_translate(audio_path):\n",
        "    # Step 1: Transcribe the audio file\n",
        "    print(\"Transcribing audio...\")\n",
        "    result = model.transcribe(audio_path)\n",
        "    transcribed_text = result[\"text\"]\n",
        "    print(\"Transcription Complete!\")\n",
        "    print(\"Transcribed Text:\", transcribed_text)\n",
        "\n",
        "    # Step 2: User Translation Choice\n",
        "    print(\"\\nSelect a translation option:\")\n",
        "    print(\"1. English to Telugu\")\n",
        "\n",
        "    choice = int(input(\"Enter your choice as 1: \"))\n",
        "\n",
        "    # Step 3: Perform Translation\n",
        "    if choice == 1:\n",
        "      translated_text = translate_large_text(transcribed_text, english_to_telugu, nllb_tokenizer)\n",
        "    else:\n",
        "        print(\"Invalid choice. Please try again.\")\n",
        "        return\n",
        "\n",
        "    # Step 4: Display Translated Text\n",
        "    print(\"Translated Text:\")\n",
        "    print(translated_text)"
      ],
      "metadata": {
        "id": "8_i8WVkouX1b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a2ywtxFN8Aq",
        "outputId": "00c196a1-e19a-4594-93cc-4c815dfaa1b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the audio file path\n",
        "audio_path = \"/content/drive/MyDrive/My Projects/Trizen/CBPT1SGA/audio.wav\"  # Replace with your file path"
      ],
      "metadata": {
        "id": "n-T5gj3gviEz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(audio_path)"
      ],
      "metadata": {
        "id": "6mB7D9FmUt3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6e3a08-bcb8-4500-b376-19781ce852fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/My Projects/Trizen/CBPT1SGA/audio.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the pipeline\n",
        "transcribe_and_translate(audio_path)"
      ],
      "metadata": {
        "id": "v7cIonnbvv_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e1fce9-8465-4763-b444-cc2278de81ac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing audio...\n",
            "Transcription Complete!\n",
            "Transcribed Text:  Today I'm going to teach you one expression, just one, because I want you to memorize it and start using it every time you speak English. This expression is extremely useful and native speakers use it all the time. Every day we come across something that is very easy or obvious to do or understand. You don't even need to think about it. It's obvious that water is wet, then the sun is hot. And it's obvious that a cat will always land on its feet. Try your own risk. So when you don't have to consider something for a long time, it's just because it's a no-brainer. It's a no-brainer that you will improve your English if you follow me here.\n",
            "\n",
            "Select a translation option:\n",
            "1. English to Telugu\n",
            "Enter your choice as 1: 1\n",
            "Translated Text:\n",
            "ఈ రోజు నేను మీకు ఒక వ్యక్తీకరణ నేర్పబోతున్నాను, ఒక్కటి మాత్రమే, ఎందుకంటే మీరు ఆంగ్లంలో మాట్లాడే ప్రతిసారీ దాన్ని గుర్తుంచుకోవాలని మరియు ఉపయోగించడం ప్రారంభించాలని నేను కోరుకుంటున్నాను. ఈ వ్యక్తీకరణ చాలా ఉపయోగకరంగా ఉంటుంది మరియు స్థానిక మాట్లాడేవారు దీన్ని అన్ని సమయాలలో ఉపయోగిస్తారు. ప్రతిరోజూ మనం చేయటానికి లేదా అర్థం చేసుకోవడానికి చాలా సులభం లేదా స్పష్టంగా ఉన్నదాన్ని ఎదుర్కొంటాము. మీరు దాని గురించి ఆలోచించాల్సిన అవసరం లేదు. నీరు తడిగా ఉందని స్పష్టంగా ఉంది, అప్పుడు సూర్యుడు వేడిగా ఉన్నాడు. మరియు పిల్లి ఎల్లప్పుడూ తన పాదాలపై భూమికి వస్తుంది. మీ స్వంత ప్రమాదాన్ని ప్రయత్నించండి. కాబట్టి మీరు ఏదో ఎక్కువ కాలం పరిగణించాల్సిన అవసరం లేనప్పుడు, అది సహజమైనది. మీరు ఇక్కడ నన్ను అనుసరించినట్లయితే మీ ఇంగ్లీష్ మెరుగుపరుస్తుంది.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fhKkptpNv1MD"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}